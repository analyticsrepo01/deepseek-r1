{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057eedda-ed39-4937-8893-db6de53b186a",
   "metadata": {},
   "source": [
    "### Deepseek Inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12468093-e46c-4952-aaf0-89739c44eabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.06k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/transformers/generation/utils.py:1375: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'user', 'content': 'How can you help me?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': \"<think>\\n\\n</think>\\n\\nI'm sorry, but I cannot\"}]}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"How can you help me?\"},\n",
    "]\n",
    "pipe = pipeline(\"text-generation\", model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3095e6fe-1bd7-4552-8290-498812e2effc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'user',\n",
       "    'content': 'you are good at writting stories ?'},\n",
       "   {'role': 'user', 'content': 'write a srort story?'},\n",
       "   {'role': 'assistant', 'content': '<think>\\n'}]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"you are good at writting stories ?\"},\n",
    "    {\"role\": \"user\", \"content\": \"write a srort story?\"}\n",
    "]\n",
    "\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecdd0dc8-6449-43c9-a724-3e9430e5e36e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write a short  story to get a learning for a kid about the importance of self respect and self control.\n",
      "Please include a setting, characters, and a plot.\n",
      "I need to make sure it's not too long but still covers the key points.\n",
      "Sure, let's create a story about a kid named Jake who is trying to learn about self respect and self control. The story should include a setting, characters, and a plot that teaches these values. It should be short but cover the main points. I'll start by setting the scene at a cozy home with a warm fire. The main character is Jake, who is curious about how to take care of himself. He decides to start by reading a book about self control, which helps him understand the importance of setting boundaries. Then, he practices talking to himself, reminding himself to stay focused and not be overwhelmed. Along the way, he meets some friends who also learn these skills, showing that it's not just about oneself but also about others. In the end, Jake feels more confident in taking care\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = pipe(\n",
    "    \"write a short  story to get a learning for a kid\",\n",
    "    max_new_tokens=200,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07130258-37df-491b-91a3-ec35d70cba3d",
   "metadata": {},
   "source": [
    "### Deepseek Install as a Model garden endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583792bd-6f72-4509-b5c8-efffe33950cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "#install this package if not Pre available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "070bacd8-e4c2-468b-8828-655e5f0e180e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ENDPOINT_ID=\"PLEASE_ADD_ENDPOINT_ID_HERE\"  #--- ENTER your endpoint \n",
    "\n",
    "PROJECT_IDS = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_IDS[0]  # @param {type:\"string\"}\n",
    "\n",
    "REGION = \"us-central1\"\n",
    "# INPUT_DATA_FILE=\"INPUT-JSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee03bb83-2f43-4651-9a8b-0f4c12e9a831",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Vertex AI API.\n"
     ]
    }
   ],
   "source": [
    "print(\"Initializing Vertex AI API.\")\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4399c750-6379-4d5f-914d-984a28ba0d7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endpoint <google.cloud.aiplatform.models.Endpoint object at 0x7fc743697730> \n",
      "resource name: projects/255766800726/locations/us-central1/endpoints/8436043646041587712\n"
     ]
    }
   ],
   "source": [
    "# endpoint_name = \"\"  # @param {type:\"string\"}\n",
    "aip_endpoint_name = (\n",
    "    f\"projects/{PROJECT_ID}/locations/{REGION}/endpoints/{ENDPOINT_ID}\"\n",
    ")\n",
    "endpoint = aiplatform.Endpoint(aip_endpoint_name)\n",
    "print(\"endpoint\",endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb882161-9609-4ec1-8394-402504ef58d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"What is the difference between co-pay and co-insurance in health insurance?\"  # @param {type: \"string\"}\n",
    "max_tokens = 200  # @param {type:\"integer\"}\n",
    "temperature = 1.0  # @param {type:\"number\"}\n",
    "top_p = 1.0  # @param {type:\"number\"}\n",
    "top_k = 1  # @param {type:\"integer\"}\n",
    "raw_response = False  # @param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdc4998f-26d0-44a7-917a-bb0604b37959",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "What is the difference between co-pay and co-insurance in health insurance?\n",
      "Output:\n",
      " I need to explain this in simple terms.\n",
      "\n",
      "Okay, so I need to figure out the difference between copay and coinsurance in health insurance. I'm a bit confused about these terms, but I'll try to break it down step by step.\n",
      "\n",
      "First, I remember that both copay and coinsurance are out-of-pocket costs you might have to pay when you go to the doctor or use medical services. But I'm not exactly sure how they differ. Let me think about what each one means.\n",
      "\n",
      "Copay, I think, is a fixed amount you pay each time you visit a healthcare provider. Like, maybe every time I go to the doctor, I have to pay $20 as a copay, regardless of how much the service costs. So it's a flat rate. That makes sense because it's a set amount, so it's predictable.\n",
      "\n",
      "On the other hand, coinsurance sounds a bit more complicated. I believe it's a percentage of the total cost of the service.\n"
     ]
    }
   ],
   "source": [
    "instances = [\n",
    "    {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"top_k\": top_k,\n",
    "        \"raw_response\": raw_response,\n",
    "    },\n",
    "]\n",
    "response = endpoint.predict(instances=instances)\n",
    "\n",
    "for prediction in response.predictions:\n",
    "    print(prediction)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
